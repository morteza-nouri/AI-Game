{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence :  Computer Assignment 2 - Game\n",
    "> __Morteza Nouri, 810198481__\n",
    "\n",
    "## Goals:\n",
    "- Learning Adversarial Search algorithm(minimax)\n",
    "- How to formulate problems (Abstraction)\n",
    "- Familiarity with decision making and game theory\n",
    "- Familiarity with a variety of game strategies (zero-sum, general , ...)\n",
    "\n",
    "## Description:\n",
    "> In this project we want to develop an agent who play connect4 game with another player. We use minimax algorithm to find different combinations of possible moves for players (using backtracking) and then choose chain of moves to win. Because the state space of moves can be very large we use heuristic function and don't explore all depths in a decision tree to reach leaves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic Function:\n",
    "\n",
    "In practice, because of resources limitation  we cannot search the decision tree to leaves. The solution is to use Depth-Limited search and replace terminal utilities with an evaluation\n",
    "function for non-terminal positions.<br>\n",
    "Evaluation function score non-terminals and it is typically weighted linear sum of features.<br>\n",
    "For this game, I use three features: 2-consecutive identical pieces, 3-consecutive identical pieces and 4-consecutive identical pieces, each has its own value. <br>\n",
    "I travese horizontally, vertically and diagonal to find mentioned features, then for one player I added this feature value to total score while for another player I subtract feature value from total score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Minimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(self):\n",
    "    \"\"\"\n",
    "    evaluate score of current board state, this method traverse in 4 direction and find 2-consecutive and 3-consecutive \n",
    "    YOU pieces and CPU pieces and then increment the score.\n",
    "\n",
    "    Outputs\n",
    "    ----------\n",
    "    returns the score of current board state\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    score += self.__horizontal_score(self.__CONNECT_NUMBER - 2)\n",
    "    score += self.__horizontal_score(self.__CONNECT_NUMBER - 1)\n",
    "    score += self.__vertical_score(self.__CONNECT_NUMBER - 2)\n",
    "    score += self.__vertical_score(self.__CONNECT_NUMBER - 1)\n",
    "    score += self.__diagonal_up_score(self.__CONNECT_NUMBER - 2)\n",
    "    score += self.__diagonal_up_score(self.__CONNECT_NUMBER - 1)\n",
    "    score += self.__diagonal_down_score(self.__CONNECT_NUMBER - 2)\n",
    "    score += self.__diagonal_down_score(self.__CONNECT_NUMBER - 1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __horizontal_score(self, consecSlice):\n",
    "    \"\"\"\n",
    "    Traverse horizontally to find consecSlice-consecutive pieces of YOU and CPU and increments for YOU pieces\n",
    "    and decrements for CPU pieces.\n",
    "\n",
    "    Inputs\n",
    "    -------\n",
    "    consecutive slice to consider in traversing\n",
    "\n",
    "    Output\n",
    "    --------\n",
    "    horizontal evaluation score of board state\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    for i in range(self.rows):\n",
    "        for j in range(self.columns - consecSlice + 1):\n",
    "            win = self.board[i][j:j+consecSlice]\n",
    "            if win == [self.YOU] * 3:\n",
    "                score += 45\n",
    "            elif win == [self.CPU] * 3:\n",
    "                score -= 45\n",
    "            elif win == [self.YOU] * 2:\n",
    "                score += 4\n",
    "            elif win == [self.CPU] * 2:\n",
    "                score -= 4\n",
    "            else: pass\n",
    "    return score\n",
    "\n",
    "def __vertical_score(self, consecSlice):\n",
    "    score = 0\n",
    "    board = np.array(self.board)\n",
    "    for j in range(self.columns):\n",
    "        col_array = [int(x) for x in list(board[:,j])]\n",
    "        for i in range(self.rows - consecSlice + 1):\n",
    "            win = col_array[i:i+consecSlice]\n",
    "            if win == [self.YOU] * 3:\n",
    "                score += 45\n",
    "            elif win == [self.CPU] * 3:\n",
    "                score -= 45\n",
    "            elif win == [self.YOU] * 2:\n",
    "                score += 4\n",
    "            elif win == [self.CPU] * 2:\n",
    "                score -= 4\n",
    "            else:\n",
    "                pass\n",
    "    return score \n",
    "\n",
    "def __diagonal_up_score(self, consecSlice):\n",
    "    score = 0\n",
    "    for r in range(self.rows - consecSlice):\n",
    "        for c in range(self.columns - consecSlice):\n",
    "            win = [self.board[r+i][c+i] for i in range(consecSlice)]\n",
    "            if win == [self.YOU] * 3:\n",
    "                score += 45\n",
    "            elif win == [self.CPU] * 3:\n",
    "                score -= 45\n",
    "            elif win == [self.YOU] * 2:\n",
    "                score += 4\n",
    "            elif win == [self.CPU] * 2:\n",
    "                score -= 4\n",
    "            else:\n",
    "                pass\n",
    "    return score \n",
    "\n",
    "def __diagonal_down_score(self, consecSlice):\n",
    "    score = 0\n",
    "    for r in range(self.rows - consecSlice):\n",
    "        for c in range(self.columns - consecSlice):\n",
    "            win = [self.board[r+consecSlice-i][c+i] for i in range(consecSlice)]\n",
    "            if win == [self.YOU] * 3:\n",
    "                score += 45\n",
    "            elif win == [self.CPU] * 3:\n",
    "                score -= 45\n",
    "            elif win == [self.YOU] * 2:\n",
    "                score += 4\n",
    "            elif win == [self.CPU] * 2:\n",
    "                score -= 4\n",
    "            else:\n",
    "                pass\n",
    "    return score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def minimax(self, depth, turn):\n",
    "    self.explored += 1\n",
    "    pm = self.get_possible_moves()\n",
    "    score = 0\n",
    "    if depth == 0 or self.check_if_player_has_won(self.YOU) or self.check_if_player_has_won(self.CPU) or len(pm) == 0:\n",
    "        if self.check_if_player_has_won(self.YOU) or self.check_if_player_has_won(self.CPU) or len(pm) == 0:\n",
    "            if self.check_if_player_has_won(self.YOU):\n",
    "                score += 1000000\n",
    "            elif self.check_if_player_has_won(self.CPU):\n",
    "                score -= 1000000\n",
    "            else:\n",
    "                score += self.evaluation()\n",
    "        else:\n",
    "            score += self.evaluation()\n",
    "\n",
    "        return None, score\n",
    "\n",
    "    boardCpy = copy.deepcopy(self.board)\n",
    "    if turn == self.YOU:  # Maximizer\n",
    "        bestValue = float('-inf')\n",
    "        column = choice(pm)\n",
    "        for m in pm:\n",
    "            if self.is_move_valid(m):\n",
    "                self.register_input(m, self.YOU)\n",
    "                value = self.minimax(depth-1, self.CPU)[1]\n",
    "                if value > bestValue:\n",
    "                    column = m\n",
    "                    bestValue = value\n",
    "            self.board = copy.deepcopy(boardCpy)\n",
    "        return column, bestValue\n",
    "\n",
    "    else:  # turn == self.CPU, Minimizer\n",
    "        bestValue = float('inf')\n",
    "        column = choice(pm)\n",
    "        for m in pm:\n",
    "            if self.is_move_valid(m):\n",
    "                self.register_input(m, self.CPU)\n",
    "                value = self.minimax(depth-1, self.YOU)[1]\n",
    "                if value < bestValue:\n",
    "                    column = m\n",
    "                    bestValue = value\n",
    "            self.board = copy.deepcopy(boardCpy)\n",
    "        return column, bestValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Minimax:\n",
    "\n",
    "| Test | Board | Depth | AvgTime(s) | TotalTime(200 executions)(s)  | WinRate(wins in 200 executions) | ExploredStates(cumulative)|\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-:|\n",
    "|1| 6 * 7 | 1 | 0.0147 | 2.9500 | 70% | 32\n",
    "|2| 6 * 7 | 3 | 0.6759 | 135.186 | 99% | 1800\n",
    "|3| 6 * 7 | 5 | 31.128 | 6743.650 | 99% | 74000\n",
    "|4| 7 * 8 | 1 | 0.0197 | 3.945 | 73% | 40\n",
    "|5| 7 * 8 | 3 | 1.1378 | 277.572 | 99.5% | 2750\n",
    "|6| 7 * 8 | 5 | 72.433 | 21319.1683 | 100% | 160000\n",
    "|7| 7 * 10| 1 | 0.0366 | 7.337847 | 80.5% | 44\n",
    "|8| 7 * 10| 3 | 3.392 | 678.5175 | 98.5% |5400\n",
    "|9| 7 * 10| 5 | 376.6435 | 75328.7 | 99% |420000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Minimax with Alpha-Beta Pruning\n",
    "__Alpha__ is the best value that the __maximizer__ currently can guarantee at that level or above. <br>\n",
    "__Beta__ is the best value that the __minimizer__ currently can guarantee at that level or above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimaxAlphaBeta(self, depth, turn, alpha = float('-inf'), beta = float('inf')):\n",
    "    self.explored += 1\n",
    "    pm = self.get_possible_moves()\n",
    "    score = 0\n",
    "    if depth == 0 or self.check_if_player_has_won(self.YOU) or self.check_if_player_has_won(self.CPU) or len(pm) == 0:\n",
    "        if self.check_if_player_has_won(self.YOU) or self.check_if_player_has_won(self.CPU) or len(pm) == 0:\n",
    "            if self.check_if_player_has_won(self.YOU):\n",
    "                score += 1000000\n",
    "            elif self.check_if_player_has_won(self.CPU):\n",
    "                score -= 1000000\n",
    "            else:\n",
    "                score += self.evaluation()\n",
    "        else:\n",
    "            score += self.evaluation()\n",
    "\n",
    "        return None, score\n",
    "\n",
    "    boardCpy = copy.deepcopy(self.board)\n",
    "    if turn == self.YOU:  # Maximizer\n",
    "        bestValue = float('-inf')\n",
    "        column = choice(pm)\n",
    "        for m in pm:\n",
    "            if self.is_move_valid(m):\n",
    "                self.register_input(m, self.YOU)\n",
    "                value = self.minimaxAlphaBeta(depth-1, self.CPU, alpha, beta)[1]\n",
    "                if value > bestValue:\n",
    "                    column = m\n",
    "                    bestValue = value\n",
    "                alpha = max(alpha, value)\n",
    "                if alpha >= beta:\n",
    "                    beta\n",
    "            self.board = copy.deepcopy(boardCpy)\n",
    "        return column, bestValue\n",
    "\n",
    "    else:  # turn == self.CPU, Minimizer\n",
    "        bestValue = float('inf')\n",
    "        column = choice(pm)\n",
    "        for m in pm:\n",
    "            if self.is_move_valid(m):\n",
    "                self.register_input(m, self.CPU)\n",
    "                value = self.minimaxAlphaBeta(depth-1, self.YOU, alpha, beta)[1]\n",
    "                if value < bestValue:\n",
    "                    column = m\n",
    "                    bestValue = value\n",
    "                beta = min(beta, value)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "            self.board = copy.deepcopy(boardCpy)\n",
    "        return column, bestValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Alpha-Beta Pruning:\n",
    "\n",
    "| Test | Board | Depth | AvgTime(s) | TotalTime(200 executions)(s)  | WinRate(wins in 200 executions) | ExploredStates(cumulative)|\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-:|\n",
    "|1| 6 * 7 | 1 | 0.0142 | 2.8493 | 68% | 30 |\n",
    "|2| 6 * 7 | 3 | 0.28001 | 56.002 | 98.5% | 800 |\n",
    "|3| 6 * 7 | 5 | 12.6825 | 2536.5 | 99% | 34600 |\n",
    "|4 | 6 * 7 | 7 | 211.915 | 42383.16 | 99.5% | 845540 |\n",
    "|5| 7 * 8 | 1 | 0.01965 | 4.345 | 71% | 36 |\n",
    "|6| 7 * 8 | 3 | 0.56511 | 113.022 | 98% | 1029 |\n",
    "|7| 7 * 8 | 5 | 14.9017 | 2980.34 | 99% | 64500 |\n",
    "|8| 7 * 8 | 7 | 243.6938|48738.76 | 99.5%| 580000 |\n",
    "|9| 7 * 10| 1 | 0.03180 | 6.46721 | 81.5% | 33 |\n",
    "|10| 7 * 10| 3 | 1.2146 | 243.12| 98.5% | 1500 |\n",
    "|11| 7 * 10| 5 | 117.7886 | 23557.72 | 98.5% |215700 |\n",
    "|12| 7 * 10| 7 | 2064.8254 | 412965.08 | 99.5% | 2980000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Answer Questions\n",
    "\n",
    "__1__: The final decision made by Minimax largely depends on how well the heuristic function is. Therefore, designing a reasonable heuristic function is paramount. So a good heuristic function should be informed and admissible. The heuristic function which considers more features is better. For example in my heuristic features that I mentioned above, if there are 3-identical-connected pieces, the probabilty of wining is high, and for 2-connected this probability is lower and etc. <br>\n",
    "another heuristic can counts all YOU and CPU pieces in the board and returns the difference between the two numbers, but this heuristic is not accurate because consecutive connected pieces are important to us.\n",
    "\n",
    "\n",
    "__2__:  As depth of searching keeps increasing, the heuristic has better functionality and win rate increases, but resource utilization(time, memory) increases instead, because we explore more states.\n",
    "\n",
    "__3__: The effectiveness of alpha-beta pruning is highly dependent on the order in which each node is examined. Move order is an important aspect of alpha-beta pruning. In worst case, algorithm doesn't prune any of the leaves of tree. In best case, lots of pruning happen in the tree and best moves occur at left side of tree. In this project I use random order for visiting nodes. but for better performance of alpha-beta pruning we can do some rules to find better ordering:\n",
    "- Order the nodes in the tree such that the best nodes are checked first.\n",
    "- We can store the states, as there is a possibility that states may repeat.\n",
    "- Occur the best move from the shallowest node.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
